# 人工智慧第十六週筆記
## 機器學習
* 在機率理論中，所謂的機率模型，通常是指某種機率獨立性的假設。
## 最大概似估計
* 在統計學中，最大概似估計（英語：Maximum Likelihood Estimation，簡作MLE），也稱極大概似估計，是用來估計一個機率模型的母數的一種方法。
## 蒙地卡羅方法 (Monte Carlo method)
* [蒙地卡羅方法](https://zh.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%96%B9%E6%B3%95)
* 擁有一個四分之一圓(以內為紅色以外為藍色)
* 蒙地卡羅方法（英語：Monte Carlo method），也稱統計類比方法，是1940年代中期由於科學技術的發展和電腦的發明，而提出的一種以機率統計理論為指導的數值計算方法。是指使用亂數（或更常見的偽亂數）來解決很多計算問題的方法。
![pic1](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic1.png)
## 黎曼積分
* 在實分析中，由黎曼創立的黎曼積分（英語：Riemann integral）首次對函數在給定區間上的積分給出了一個精確定義。黎曼積分在技術上的某些不足之處可由後來的黎曼－斯蒂爾傑斯積分和勒貝格積分得到修補。
![pic2](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic2.png)
## 馬可夫鏈 (Markov chain)
* [馬可夫鏈](https://zh.wikipedia.org/zh-tw/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)
* 討論不是互相獨立的一些事件。
* 下一狀態的機率分布只能由當前狀態決定，在時間序列中它前面的事件均與之無關。
* 種具有狀態的隨機過程
* ex: 轉移矩陣的應用問題
![pic3](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic3.png)
## 吉布斯採樣 (Gibbs sampling)
* [吉布斯採樣](https://zh.wikipedia.org/wiki/%E5%90%89%E5%B8%83%E6%96%AF%E9%87%87%E6%A0%B7)
* 吉布斯採樣（英語：Gibbs sampling）是統計學中用於馬爾科夫蒙特卡洛（MCMC）的一種算法，用於在難以直接採樣時從某一多變量概率分布中近似抽取樣本序列。該序列可用於近似聯合分布、部分變量的邊緣分布或計算積分（如某一變量的期望值）。某些變量可能為已知變量，故對這些變量並不需要採樣。
 ![pic4](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic4.png)
## 隱藏式馬可夫模型
* [隱藏式馬可夫模型](https://zh.wikipedia.org/zh-tw/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B)
* 隱藏式馬可夫模型（Hidden Markov Model；縮寫：HMM）或稱作隱性馬可夫模型，是統計模型，它用來描述一個含有隱含未知參數的馬可夫過程。其難點是從可觀察的參數中確定該過程的隱含參數。然後利用這些參數來作進一步的分析，例如圖型識別。
![pic5](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic5.png)
## 維特比演算法（Viterbi algorithm）
* [維特比演算法](https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95)
* 維特比演算法（英語：Viterbi algorithm）是一種動態規劃演算法。它用於尋找最有可能產生觀測事件序列的維特比路徑——隱含狀態序列，特別是在馬可夫資訊源上下文和隱藏式馬可夫模型中。

![pic6]](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic6.png)

##　EM 演算法實作
* [EM演算法](https://programmermedia.org/root/%E9%99%B3%E9%8D%BE%E8%AA%A0/%E8%AA%B2%E7%A8%8B/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/06-learn/05-em/em.md)
* 上述 EM 演算法問題的背後，其實是一種「最大概似估計」，只是加入了「隱變數」的概念，這種「最大概似估計」企圖最大化下列算式中的θ值。
* 這個範例探討的是兩個「不公正的銅板」 A 與 B，兩者正面的機率分別是  與  ，當我們用這兩的銅板進行一系列的抽樣時，得到了下列的結果。
![pic7](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic7.png)
![pic8](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic8.png)
* θA和θB之初值可隨便設，雖不知實驗時是A還是B但可算出期望值。
   ex: 第一次的期望值  
![pic9](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic9.png)

* 再利用此機率去計算銅板正面及反面的期望值。
    * ex: P(A) (#H, #T) = 0.45 (5H, 5T) = (2.25 H, 2.25T) ~ (2.2H, 2.2T) 
* 將H和T加總可求出新的θA和θB
![pic10](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic10.png) 
* 按照循環可找出最後的結果
## K-近鄰演算法
* [K-近鄰演算法](https://zh.wikipedia.org/wiki/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95)
* 在圖型識別領域中，最近鄰居法（KNN演算法，又譯K-近鄰演算法）是一種用於分類和迴歸的無母數統計方法。在這兩種情況下，輸入包含特徵空間（Feature Space）中的k個最接近的訓練樣本。
![pic11](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic11.png)
## 決策樹
* [決策樹](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda)
* [決策樹維基百科](https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91)
* 決策論中 （如風險管理），決策樹（Decision tree）由一個決策圖和可能的結果（包括資源成本和風險）組成， 用來創建到達目標的規劃。決策樹建立並用來輔助決策，是一種特殊的樹結構。決策樹是一個利用像樹一樣的圖形或決策模型的決策支持工具，包括隨機事件結果，資源代價和實用性。
![pic12](https://github.com/www-abcdefg/ai109b/blob/main/pic/16%E9%80%B1/pic12.png)
## sklearn
* ko@ko-VirtualBox:~/課程/ai/06-learn/07-classify$ pip install sklearn
## code
* monteCarloPi.py
    * hits在圓內 n所有
```
'''
參考圖： https://zh.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%96%B9%E6%B3%95#/media/File:Pi_30K.gif

四分之一圓的面積 pi/4
正方形面積為 1

落在圓裡面的點 / 所有點 = 四分之一圓的面積 / 正方形面積 = pi/4

pi = 4 * (落在圓裡面的點 / 所有點) = 4 * (hits / n)
'''
from random import random

def monteCarloPi(n):
    hits = 0
    for _ in range(n):
        x = random()
        y = random()
        if (x*x+y*y <= 1):
            hits += 1
    return 4*(hits/n)

print('MonteCarloPi(100000)=', monteCarloPi(100000))
```
* 執行結果
```
ko@ko-VirtualBox:~$ cd 課程
ko@ko-VirtualBox:~/課程$ cd ai
ko@ko-VirtualBox:~/課程/ai$ cd 06-learn
ko@ko-VirtualBox:~/課程/ai/06-learn$ cd 01-montecarlo
ko@ko-VirtualBox:~/課程/ai/06-learn/01-montecarlo$ python3 monteCarloPi.py
MonteCarloPi(100000)= 3.14016
```
* map/markov.py
    * 馬可夫鏈
```
# 參考： 自然語言處理 -- Hidden Markov Model http://cpmarkchang.logdown.com/posts/192352
from prob import P

def markov(s):
    p = P[s[0]]
    for i in range(1, len(s)):
        key = s[i-1]+'=>'+s[i]
        p = p * P[key]
    return p

seq = ['b', 'a', 'b', 'b']

print('P(b a b b) = P(b) P(b=>a) P(a=>b) P(b=>b) = {}*{}*{}*{} = {}'.format(P['b'], P['b=>a'], P['a=>b'], P['b=>b'], markov(seq)))

```
* matrix/markov.py
```
# 參考： 自然語言處理 -- Hidden Markov Model http://cpmarkchang.logdown.com/posts/192352
from prob import *

def markov(s):
    p = P[s[0]]
    for i in range(1, len(s)):
        p = p * T[s[i-1]][s[i]]
    return p

seq = [b, a, b, b]

print('P(b a b b) = P(b) P(b=>a) P(a=>b) P(b=>b) = {}*{}*{}*{} = {}'.format(P[b], T[b][a], T[a][b], T[b][b], markov(seq)))
```
* 執行結果
```
ko@ko-VirtualBox:~/課程/ai/06-learn/02-markov$ cd map
ko@ko-VirtualBox:~/課程/ai/06-learn/02-markov/map$ python3 markov.py
P(b a b b) = P(b) P(b=>a) P(a=>b) P(b=>b) = 0.8*0.5*0.3*0.5 = 0.06
ko@ko-VirtualBox:~/課程/ai/06-learn/02-markov$ cd matrix
ko@ko-VirtualBox:~/課程/ai/06-learn/02-markov/matrix$ python3 markov.py
P(b a b b) = P(b) P(b=>a) P(a=>b) P(b=>b) = 0.8*0.5*0.3*0.5 = 0.06
```
* gibbs.py
    * 吉布斯採樣
```
# Gibbs Algorithm 的範例
# 問題：機率式有限狀態機，P(a=>b)=0.3, P(b=>a)=0.5 ; P(a=>b)=0.7, P(b=>b)=0.5
# 目標：尋找該「機率式有限狀態機」的穩態，也就是 P(a) = ?, P(b)=? 時系統會達到平衡。
from prob import P
import math

def gibbs (P):
    P0 = {'a': P['a'], 'b': P['b'] }
    print('P0 = {}'.format(P0))
    while True:
        P1 = { # 下一輪的機率分布。
            'a': P0['a'] * P['a=>a'] + P0['b'] * P['b=>a'], 
            'b': P0['a'] * P['a=>b'] + P0['b'] * P['b=>b']
        }
        print('P1 = {}'.format(P1))
        da = P1['a'] - P0['a']
        db = P1['b'] - P0['b'] # 兩輪間的差異。
        step = math.sqrt(da * da + db * db) # 差異的大小
        P0 = P1
        if (step < 0.001): break # 假如差異夠小的時候，就可以停止了。

    print('標準答案:P(a)=5/8={} P(b)=3/8={}'.format(5 / 8, 3 / 8)) # 印出標準答案，以便看看我們找到的答案是否夠接近。

gibbs(P)
```
* 執行結果
```
ko@ko-VirtualBox:~/課程/ai/06-learn/02-markov/map$ python3 gibbs.py
P0 = {'a': 0.2, 'b': 0.8}
P1 = {'a': 0.54, 'b': 0.46}
P1 = {'a': 0.608, 'b': 0.392}
P1 = {'a': 0.6215999999999999, 'b': 0.37839999999999996}
P1 = {'a': 0.62432, 'b': 0.37567999999999996}
P1 = {'a': 0.624864, 'b': 0.37513599999999997}
標準答案:P(a)=5/8=0.625 P(b)=3/8=0.375
```
* viterbi.py
    * 維特比演算法
```
'''
參考： https:#zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95
N 0.6 => 喵 0.4 | 汪 0.6
V 0.4 => 喵 0.5 | 汪 0.5
   N   V
N  0.3 0.7
V  0.8 0.2
'''

P = {
  'N': 0.6,
  'V': 0.4,
  'N=>N': 0.3,
  'N=>V': 0.7,
  'V=>N': 0.8,
  'V=>V': 0.2,
  'N=>喵': 0.4,
  'N=>汪': 0.6,
  'V=>喵': 0.5,
  'V=>汪': 0.5,
}

def argmax(alist):
    max = -999999
    index = None
    for k in range(len(alist)):
        if alist[k] > max:
            index=k
            max=alist[k]
    return max, index

def viterbi(obs, states, P):
    print('觀察到的序列=', obs)
    T = [{} for _ in range(len(obs)+1)] # [{}]*(len(obs)+1) # Viterbi Table
    print('T=', T)
    path = {}  # path[state] = 從 0 到 t 到達 state 機率最大的 path

    for y in states: # Initialize base cases (t == 0)
        T[0][y] = P[y] * P[y+'=>'+obs[0]]
        path[y] = [y]

    for t in range(1, len(obs)): # Run Viterbi for t > 0
        newpath = {}
        for y in states:
            prob, si = argmax(list(map(lambda y0:T[t-1][y0] * P[y0+'=>'+y] * P[y+'=>'+obs[t]], states)))
            state = states[si]
            T[t][y] = prob
            newpath[y] = path[state] + [y] # concat(path[state], y)
        path = newpath
        print('t={} path={}'.format(t, path))

    prob, si = argmax(list(map(lambda y:T[len(obs) - 1][y], states)))
    print('T=', T)
    return [prob, path[states[si]]]

prob, path = viterbi('喵 喵 汪'.split(' '), ['N', 'V'], P)
print('prob={} path={}＝最可能的隱序列'.format(prob, path))
```
* 執行結果
```
ko@ko-VirtualBox:~/課程/ai/06-learn$ cd 04-hmm
ko@ko-VirtualBox:~/課程/ai/06-learn/04-hmm$ python3 viterbi.py
觀察到的序列= ['喵', '喵', '汪']
T= [{}, {}, {}, {}]
t=1 path={'N': ['V', 'N'], 'V': ['N', 'V']}
t=2 path={'N': ['N', 'V', 'N'], 'V': ['V', 'N', 'V']}
T= [{'N': 0.24, 'V': 0.2}, {'N': 0.06400000000000002, 'V': 0.08399999999999999}, {'N': 0.040319999999999995, 'V': 0.022400000000000003}, {}]
prob=0.040319999999999995 path=['N', 'V', 'N']＝最可能的隱序列
```
* em.py
```
import numpy as np
import math
# 參考文獻：Numerical example to understand Expectation-Maximization -- http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf
# What is the expectation maximization algorithm? (PDF) -- http://stats.stackexchange.com/questions/72774/numerical-example-to-understand-expectation-maximization

'''
計算 P(e|p)

ex: logP(e1|pA) = logP([5,5]|[0.6,0.4]) 
               = log(0.6^5*0.4^5) 
               = 5 log(0.6) + 5 log(0.4)

最後 P(e1|pA) = exp(logP(e1|pA)) = 0.6^5 + 0.4^5
'''
def P(e, p):
    logP = np.dot(e, np.log(p))
    return np.exp(logP)

'''
1st:  Coin B, {HTTTHHTHTH}, 5H,5T
2nd:  Coin A, {HHHHTHHHHH}, 9H,1T
3rd:  Coin A, {HTHHHHHTHH}, 8H,2T
4th:  Coin B, {HTHTTTHHTT}, 4H,6T
5th:  Coin A, {THHHTHHHTH}, 7H,3T
假如已經知道，1st, 4th 是 B, 2nd, 3rd, 5th 是 A, 
那就可以計算出 pA(heads) = 0.80 and pB(heads)=0.45
'''
def EM():
    e = [ [5,5], [9,1], [8,2], [4,6], [7,3] ]
    pA = [0.6, 0.4]
    pB = [0.5, 0.5]
    delta = 9.9999
    for _ in range(1000):
        print("pA={} pB={} delta={}".format(pA, pB, delta))
        sumA=[0,0]
        sumB=[0,0]
        for ei in e:
            # estimate
            a = P(ei, pA) # 用 A 去擲會產生 ei 的機率之 log
            b = P(ei, pB)
            wA = a/(a+b)   # = a 的權重
            wB = b/(a+b)   # = b 的權重
            eA = np.multiply(wA, ei) # A 的估計值
            eB = np.multiply(wB, ei) # B 的估計值
            # estimation 完成估計
            # maximization （先加總）
            sumA = np.add(sumA, eA)
            sumB = np.add(sumB, eB)

        npA = np.multiply(sumA, 1.0/np.sum(sumA)) # 新一版的 pA
        npB = np.multiply(sumB, 1.0/np.sum(sumB)) # 新一版的 pB
        # 計算差異，看看是否該停止了
        dA  = np.subtract(npA, pA)
        dB  = np.subtract(npB, pB)
        delta = np.max([dA, dB])
        if delta < 0.001: break
        # 更新 pA, pB 為新一版
        pA = npA
        pB = npB

EM()
```
* 執行結果
```
ko@ko-VirtualBox:~/課程/ai/06-learn/05-em$ python3 em.py
pA=[0.6, 0.4] pB=[0.5, 0.5] delta=9.9999
pA=[0.71301224 0.28698776] pB=[0.58133931 0.41866069] delta=0.11301223540051619
pA=[0.74529204 0.25470796] pB=[0.56925575 0.43074425] delta=0.0322798006814784
pA=[0.76809883 0.23190117] pB=[0.54953591 0.45046409] delta=0.022806798285326613
pA=[0.78316458 0.21683542] pB=[0.53461745 0.46538255] delta=0.015065749932652417
pA=[0.79105525 0.20894475] pB=[0.52628117 0.47371883] delta=0.008336287117588381
pA=[0.79453254 0.20546746] pB=[0.52239044 0.47760956] delta=0.003890729512057156
pA=[0.79592867 0.20407133] pB=[0.52072988 0.47927012] delta=0.001660559431849007
```
* knn,py
```
# 來源 -- https://ithelp.ithome.com.tw/articles/10197110
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import numpy as np

iris = datasets.load_iris()

iris_data = iris.data
iris_label = iris.target

train_data , test_data , train_label , test_label = train_test_split(iris_data,iris_label,test_size=0.2)

knn = KNeighborsClassifier() # n_neighbors=5
# knn = KNeighborsClassifier(n_neighbors=1)
# knn = KNeighborsClassifier(n_neighbors=3)
# knn = KNeighborsClassifier(n_neighbors=37)

knn.fit(train_data,train_label)

print('預測答案：', knn.predict(test_data))
print('正確答案：', test_label)
```
* 執行結果
```
ko@ko-VirtualBox:~/課程/ai/06-learn/07-classify$ python3 knn.py
預測答案： [0 0 0 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 0 2 0 1 1 1 1 2 2 1 1 0]
正確答案： [0 0 0 2 1 1 1 1 1 2 2 1 1 2 1 1 2 2 0 2 0 1 1 1 1 2 2 1 1 0]
```
* iris1.py
```
# 程式來源 -- https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda
'''
Created on July 7, 2019
@author: Terry
@email：terryluohello@qq.com
'''
print(__doc__)

import numpy as np 
import matplotlib.pyplot as plt 

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, plot_tree

# Parameter
n_classes = 3
plot_colors = "ryb"
plot_step = 0.02

# Load data
iris = load_iris()

for pairidx, pair in enumerate([[0,1],[0,2],[0,3],
                                [1,2],[1,3],[2,3]]):
    # We only take two corresponding features
    X = iris.data[:,pair]
    y = iris.target

    # Train
    clf = DecisionTreeClassifier().fit(X,y)

    # Plot the descision boundary
    plt.subplot(2,3,pairidx + 1)
    x_min, x_max = X[:,0].min() - 1, X[:,0].max() - 1
    y_min, y_max = X[:,1].min() - 1, X[:,1].max() - 1
    xx, yy = np.meshgrid(np.arange(x_min,x_max,plot_step),
                        np.arange(y_min,y_max,plot_step))
    plt.tight_layout(h_pad=0.5,w_pad=0.5,pad=2.5)

    Z = clf.predict(np.c_[xx.ravel(),yy.ravel()])
    Z = Z.reshape(xx.shape)
    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)
    plt.xlabel(iris.feature_names[pair[0]])
    plt.ylabel(iris.feature_names[pair[1]])
    
    # Plot the training points
    for i, color in zip(range(n_classes),plot_colors):
        idx = np.where(y == i)
        plt.scatter(X[idx,0],X[idx,1],c=color,label=iris.target_names[i],
                    cmap=plt.cm.RdYlBu,edgecolors='black',s=15)
plt.suptitle("Decision surface of a decision tree using paired features")
plt.legend(loc='lower right', borderpad=0, handletextpad=0)
plt.axis("tight")

plt.figure()
clf = DecisionTreeClassifier().fit(iris.data, iris.target)
plot_tree(clf, filled=True)
plt.show()
```
* decisionTree1.py
```
from sklearn import tree
X = [[0, 0], [1, 1]]
Y = [0, 1]
clf = tree.DecisionTreeClassifier()
clf = clf.fit(X, Y)
clf.predict([[2., 2.]])
r = clf.predict_proba([[2., 2.]])
print(r)

```
* 執行結果
```
ko@ko-VirtualBox:~/課程/ai/06-learn/08-decisionTree$ python3 decisionTree1.py
[[0. 1.]]
ko@ko-VirtualBox:~/課程/ai/06-learn/08-decisionTree$ python3 iris1.py

Created on July 7, 2019
@author: Terry
@email：terryluohello@qq.com
```